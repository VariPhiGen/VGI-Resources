# üñºÔ∏è Mastering CNN Image Classification

A comprehensive tutorial on building Convolutional Neural Networks (CNNs) for image classification using TensorFlow/Keras. This repository demonstrates how to classify flower images, handle overfitting, and deploy models to mobile devices using TensorFlow Lite.

---

## üì∫ Video Tutorial

[![Mastering CNN Image Classification Tutorial](https://img.youtube.com/vi/OzD6PKBt4ZM/maxresdefault.jpg)](https://www.youtube.com/watch?v=OzD6PKBt4ZM)

**Watch the complete explanation:** [YouTube Video](https://www.youtube.com/watch?v=OzD6PKBt4ZM)

---

## üìã Table of Contents

- [Overview](#overview)
- [What You'll Learn](#what-youll-learn)
- [Prerequisites](#prerequisites)
- [Installation](#installation)
- [Project Structure](#project-structure)
- [Dataset](#dataset)
- [Notebook Contents](#notebook-contents)
- [Key Concepts Explained](#key-concepts-explained)
- [Model Architecture](#model-architecture)
- [Techniques Demonstrated](#techniques-demonstrated)
- [Results & Insights](#results--insights)
- [TensorFlow Lite Deployment](#tensorflow-lite-deployment)
- [How to Use](#how-to-use)
- [Additional Resources](#additional-resources)

---

## üéØ Overview

This project provides a hands-on guide to CNN-based image classification, covering:

- **Building CNN models** from scratch using TensorFlow/Keras
- **Loading and preprocessing image data** efficiently
- **Understanding overfitting** in image classification
- **Implementing data augmentation** techniques
- **Applying regularization** (Dropout) to improve generalization
- **Converting models to TensorFlow Lite** for mobile deployment
- **Making predictions** on new images

The notebook uses the **Flower Photos dataset** with 5 classes (daisy, dandelion, roses, sunflowers, tulips) to demonstrate real-world image classification.

---

## üéì What You'll Learn

By working through this notebook, you will:

‚úÖ Build CNN architectures using Conv2D and MaxPooling2D layers  
‚úÖ Load image datasets efficiently using `tf.keras.utils.image_dataset_from_directory`  
‚úÖ Understand and detect overfitting in image classification models  
‚úÖ Implement data augmentation (RandomFlip, RandomRotation, RandomZoom)  
‚úÖ Apply Dropout regularization to reduce overfitting  
‚úÖ Optimize data loading with caching and prefetching  
‚úÖ Visualize training progress and model performance  
‚úÖ Convert Keras models to TensorFlow Lite format  
‚úÖ Deploy models for on-device inference  
‚úÖ Make predictions on new, unseen images  

---

## üì¶ Prerequisites

Before you begin, make sure you have:

- **Python 3.7+** installed
- Basic understanding of **machine learning** and **deep learning** concepts
- Familiarity with **Python programming**
- Knowledge of **NumPy** and **Matplotlib** (helpful but not required)
- Understanding of **image processing basics** (optional but beneficial)

---

## üöÄ Installation

### Step 1: Clone or Download this Repository

```bash
git clone <repository-url>
cd VGI_Resources/Mastering_CNN_Image_Classification.
```

### Step 2: Install Required Packages

The notebook will automatically download the dataset, but you need to install the required packages:

```bash
pip install tensorflow matplotlib numpy pillow
```

Or install all at once:

```bash
pip install tensorflow matplotlib numpy pillow
```

**Note:** TensorFlow includes Keras, so you don't need to install it separately.

---

## üìÅ Project Structure

```
Mastering_CNN_Image_Classification./
‚îÇ
‚îú‚îÄ‚îÄ classification.ipynb    # Main notebook with CNN implementation
‚îî‚îÄ‚îÄ README.md               # This file
```

---

## üå∏ Dataset

### Flower Photos Dataset

The tutorial uses a dataset of **3,700 photos of flowers** with 5 classes:

1. **Daisy** üåº
2. **Dandelion** üåø
3. **Roses** üåπ
4. **Sunflowers** üåª
5. **Tulips** üå∑

**Dataset Details:**
- **Total Images:** ~3,670
- **Format:** JPG images
- **Structure:** Organized in subdirectories (one per class)
- **Source:** Automatically downloaded from TensorFlow's example datasets

**Dataset Structure:**
```
flower_photos/
  ‚îú‚îÄ‚îÄ daisy/
  ‚îú‚îÄ‚îÄ dandelion/
  ‚îú‚îÄ‚îÄ roses/
  ‚îú‚îÄ‚îÄ sunflowers/
  ‚îî‚îÄ‚îÄ tulips/
```

The dataset is automatically downloaded when you run the notebook, so no manual download is required!

---

## üìö Notebook Contents

### 1. **Setup and Data Loading**

- Import necessary libraries (TensorFlow, Keras, Matplotlib, NumPy, PIL)
- Download and explore the flower photos dataset
- Load images using `tf.keras.utils.image_dataset_from_directory`
- Split data into training (80%) and validation (20%) sets
- Visualize sample images from the dataset

### 2. **Data Preprocessing**

- Configure dataset for performance (caching and prefetching)
- Standardize pixel values to [0, 1] range using Rescaling layer
- Set image dimensions (180x180 pixels)
- Batch size configuration (32 images per batch)

### 3. **Basic CNN Model**

Build a baseline CNN model with:
- **Input Layer:** Rescaling (normalization)
- **Convolutional Blocks:** 3 blocks with increasing filters (16 ‚Üí 32 ‚Üí 64)
- **MaxPooling:** After each convolutional layer
- **Fully Connected:** Dense layer with 128 units
- **Output:** 5 classes (one for each flower type)

### 4. **Training and Evaluation**

- Compile model with Adam optimizer
- Train for 10 epochs
- Visualize training/validation accuracy and loss
- Identify overfitting issues

### 5. **Overfitting Mitigation**

Implement two key techniques:

**a) Data Augmentation:**
- Random horizontal flips
- Random rotations (¬±10%)
- Random zoom (¬±10%)

**b) Dropout Regularization:**
- Add Dropout layer (0.2 rate) before the fully connected layer

### 6. **Improved Model Training**

- Retrain with augmented data and dropout
- Compare results with baseline model
- Visualize improved training curves

### 7. **Making Predictions**

- Load and preprocess new images
- Make predictions on unseen data
- Display confidence scores

### 8. **TensorFlow Lite Conversion**

- Convert Keras model to TensorFlow Lite format
- Load and test the Lite model
- Compare predictions between original and Lite models
- Prepare for mobile/edge device deployment

---

## üîë Key Concepts Explained

### 1. **Convolutional Neural Networks (CNNs)**

CNNs are specialized neural networks designed for processing grid-like data (images). They use:

- **Convolutional Layers (Conv2D):** Detect features like edges, textures, and patterns
- **Pooling Layers (MaxPooling2D):** Reduce spatial dimensions and computational cost
- **Fully Connected Layers (Dense):** Make final classifications based on extracted features

### 2. **Data Augmentation**

Data augmentation artificially expands your training dataset by applying random transformations:

- **RandomFlip:** Mirrors images horizontally/vertically
- **RandomRotation:** Rotates images by random angles
- **RandomZoom:** Zooms in/out on images

**Benefits:**
- Increases dataset size without collecting new data
- Helps model generalize better
- Reduces overfitting
- Makes model more robust to variations

### 3. **Overfitting in Image Classification**

Overfitting occurs when the model memorizes training data instead of learning general patterns.

**Signs:**
- High training accuracy but low validation accuracy
- Large gap between train and validation metrics
- Validation loss increases while training loss decreases

**Solutions:**
- Data augmentation
- Dropout regularization
- More training data
- Simpler model architecture

### 4. **Dropout Regularization**

Dropout randomly sets a fraction of neurons to zero during training:

- **Rate:** Typically 0.2-0.5 (20-50% of neurons)
- **Effect:** Prevents co-adaptation of neurons
- **Result:** Better generalization, reduced overfitting
- **Note:** Only active during training, not inference

### 5. **TensorFlow Lite**

TensorFlow Lite is a lightweight solution for running ML models on mobile and edge devices:

- **Smaller model size:** Optimized for mobile deployment
- **Faster inference:** Optimized for on-device execution
- **Lower latency:** Runs directly on device
- **Privacy:** Data stays on device

---

## üèóÔ∏è Model Architecture

### Baseline CNN Model

```
Input (180x180x3)
    ‚Üì
Rescaling (normalize to [0,1])
    ‚Üì
Conv2D (16 filters, 3x3) + ReLU
    ‚Üì
MaxPooling2D (2x2)
    ‚Üì
Conv2D (32 filters, 3x3) + ReLU
    ‚Üì
MaxPooling2D (2x2)
    ‚Üì
Conv2D (64 filters, 3x3) + ReLU
    ‚Üì
MaxPooling2D (2x2)
    ‚Üì
Flatten
    ‚Üì
Dense (128 units) + ReLU
    ‚Üì
Dense (5 units) ‚Üí Output (5 flower classes)
```

### Improved Model (with Augmentation & Dropout)

```
Input (180x180x3)
    ‚Üì
Data Augmentation (RandomFlip, RandomRotation, RandomZoom)
    ‚Üì
Rescaling (normalize to [0,1])
    ‚Üì
Conv2D (16 filters, 3x3) + ReLU
    ‚Üì
MaxPooling2D (2x2)
    ‚Üì
Conv2D (32 filters, 3x3) + ReLU
    ‚Üì
MaxPooling2D (2x2)
    ‚Üì
Conv2D (64 filters, 3x3) + ReLU
    ‚Üì
MaxPooling2D (2x2)
    ‚Üì
Dropout (0.2) ‚Üê Added for regularization
    ‚Üì
Flatten
    ‚Üì
Dense (128 units) + ReLU
    ‚Üì
Dense (5 units) ‚Üí Output (5 flower classes)
```

---

## üõ†Ô∏è Techniques Demonstrated

### Data Loading Techniques

1. **`image_dataset_from_directory`**
   ```python
   train_ds = tf.keras.utils.image_dataset_from_directory(
       data_dir,
       validation_split=0.2,
       subset="training",
       seed=123,
       image_size=(img_height, img_width),
       batch_size=batch_size
   )
   ```

2. **Caching and Prefetching**
   ```python
   train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)
   ```

### Data Augmentation

```python
data_augmentation = keras.Sequential([
    layers.RandomFlip("horizontal", input_shape=(img_height, img_width, 3)),
    layers.RandomRotation(0.1),
    layers.RandomZoom(0.1),
])
```

### Regularization

```python
layers.Dropout(0.2)  # Drops 20% of neurons during training
```

### Model Compilation

```python
model.compile(
    optimizer='adam',
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
    metrics=['accuracy']
)
```

### TensorFlow Lite Conversion

```python
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()
```

---

## üìä Results & Insights

### Baseline Model Performance

- **Training Accuracy:** Increases linearly, reaching high values
- **Validation Accuracy:** Stalls around 60%
- **Issue:** Clear signs of overfitting
- **Gap:** Large difference between train and validation metrics

### Improved Model Performance

After applying data augmentation and dropout:

- **Training Accuracy:** More stable, realistic values
- **Validation Accuracy:** Closer to training accuracy
- **Generalization:** Better performance on unseen data
- **Overfitting:** Significantly reduced

### Key Improvements

1. **Data Augmentation:** Exposes model to more variations
2. **Dropout:** Prevents over-reliance on specific features
3. **Better Alignment:** Training and validation metrics are closer
4. **Generalization:** Model performs better on new images

---

## üì± TensorFlow Lite Deployment

### Why TensorFlow Lite?

- **Mobile Deployment:** Run models on smartphones and tablets
- **Edge Devices:** Deploy on IoT devices and embedded systems
- **Privacy:** Keep data on-device, no cloud required
- **Offline Inference:** Works without internet connection
- **Low Latency:** Faster predictions on-device

### Conversion Process

1. **Train Keras Model:** Build and train your CNN
2. **Convert to TFLite:** Use `TFLiteConverter`
3. **Save Model:** Export as `.tflite` file
4. **Load and Test:** Verify predictions match original model
5. **Deploy:** Integrate into mobile/edge applications

### Usage Example

```python
# Convert
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

# Save
with open('model.tflite', 'wb') as f:
    f.write(tflite_model)

# Load and use
interpreter = tf.lite.Interpreter(model_path='model.tflite')
classify_lite = interpreter.get_signature_runner('serving_default')
predictions = classify_lite(sequential_1_input=img_array)['outputs']
```

---

## üíª How to Use

### Option 1: Jupyter Notebook

1. Open the notebook in Jupyter:
   ```bash
   jupyter notebook classification.ipynb
   ```

2. Run cells sequentially to follow along with the tutorial

3. Experiment with different parameters:
   - Change image dimensions
   - Modify batch sizes
   - Adjust augmentation parameters
   - Try different dropout rates
   - Experiment with model architecture

### Option 2: Google Colab

1. Upload the notebook to Google Colab
2. Run all cells (the dataset will be downloaded automatically)
3. Take advantage of free GPU resources for faster training

### Option 3: VS Code / Other IDEs

1. Install the Jupyter extension
2. Open the `.ipynb` file
3. Run cells interactively
4. Use GPU acceleration if available

---

## üé® Visualizations

The notebook includes several visualizations:

- **Sample Images:** Display images from each class
- **Augmented Images:** Show data augmentation effects
- **Training Curves:** Plot accuracy and loss over epochs
- **Comparison Plots:** Compare baseline vs improved model
- **Prediction Results:** Visualize predictions on new images

---

## üîç Key Takeaways

1. **Start with a Baseline:** Build a simple model first to establish performance
2. **Monitor Both Metrics:** Always track training AND validation metrics
3. **Detect Overfitting Early:** Look for gaps between train and validation
4. **Use Data Augmentation:** Especially important for small datasets
5. **Apply Regularization:** Dropout helps prevent overfitting
6. **Optimize Data Loading:** Caching and prefetching improve training speed
7. **Consider Deployment:** TensorFlow Lite enables mobile/edge deployment
8. **Experiment:** Try different architectures and hyperparameters

---

## üìù Important Notes

- **Dataset Download:** The flower photos dataset is automatically downloaded when you run the notebook
- **Training Time:** Training time depends on your hardware (CPU/GPU)
- **Image Size:** Images are resized to 180x180 pixels for consistency
- **Data Augmentation:** Only active during training, not during inference
- **Dropout:** Only active during training, automatically disabled during inference
- **TensorFlow Lite:** The converted model is saved as `model.tflite` in the current directory

---

## üöÄ Next Steps

After completing this tutorial, you can:

1. **Experiment with Architectures:**
   - Add more convolutional layers
   - Try different filter sizes
   - Experiment with different activation functions

2. **Advanced Techniques:**
   - Transfer learning with pre-trained models (VGG, ResNet, etc.)
   - Fine-tuning pre-trained models
   - Learning rate scheduling
   - Early stopping callbacks

3. **Deployment:**
   - Build a mobile app using TensorFlow Lite
   - Create a web application with Flask/FastAPI
   - Deploy to cloud platforms (AWS, GCP, Azure)

4. **Other Datasets:**
   - Try the same approach on different image datasets
   - Work with your own custom image datasets
   - Experiment with different image sizes and formats

---

## üìñ Additional Resources

### Official Documentation

- [TensorFlow Image Classification Tutorial](https://www.tensorflow.org/tutorials/images/classification)
- [Keras Sequential Model Guide](https://www.tensorflow.org/guide/keras/sequential_model)
- [TensorFlow Lite Documentation](https://www.tensorflow.org/lite)
- [Data Augmentation Guide](https://www.tensorflow.org/tutorials/images/data_augmentation)

### Related Tutorials

- [Transfer Learning with TensorFlow](https://www.tensorflow.org/tutorials/images/transfer_learning)
- [Save and Load Models](https://www.tensorflow.org/tutorials/keras/save_and_load)
- [Better Performance with tf.data API](https://www.tensorflow.org/guide/data_performance)

### Datasets

- [TensorFlow Datasets](https://www.tensorflow.org/datasets)
- [Kaggle Datasets](https://www.kaggle.com/datasets)
- [ImageNet](https://www.image-net.org/)

---

## ü§ù Contributing

Contributions are welcome! If you have suggestions for improvements:

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

---

## üìß Contact

For questions or feedback about this tutorial, please refer to the YouTube video comments or open an issue in the repository.

---

## üìÑ License

This project is based on the TensorFlow tutorial and is open source. The original tutorial is licensed under the Apache License 2.0.

---

## ‚≠ê Acknowledgments

- **TensorFlow Team** for the excellent tutorials and documentation
- **Flower Photos Dataset** creators
- **Keras** development team
- **Open Source Community** for continuous improvements

---

## üéØ Summary

This tutorial provides a complete guide to:

‚úÖ Building CNN models for image classification  
‚úÖ Handling image data efficiently  
‚úÖ Detecting and fixing overfitting  
‚úÖ Implementing data augmentation  
‚úÖ Applying regularization techniques  
‚úÖ Converting models for mobile deployment  
‚úÖ Making predictions on new images  

**Perfect for:** Beginners learning CNNs, developers building image classification systems, and anyone interested in deploying ML models to mobile devices.

---

**Happy Learning! üöÄ**

*Remember: Practice makes perfect. Don't hesitate to experiment with different architectures, hyperparameters, and datasets!*

