{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcb371c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all ok!\n"
     ]
    }
   ],
   "source": [
    "print(\"all ok!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e217c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e0f78ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"/Users/aryan/Desktop/moondream-variphi/LMS_Experiment/Object_detection_video/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faa5b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 Person, 40.0ms\n",
      "Speed: 1.2ms preprocess, 40.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Boots, 1 Person, 36.4ms\n",
      "Speed: 1.0ms preprocess, 36.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 38.2ms\n",
      "Speed: 1.1ms preprocess, 38.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Person, 35.2ms\n",
      "Speed: 1.0ms preprocess, 35.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 37.4ms\n",
      "Speed: 0.7ms preprocess, 37.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.7ms\n",
      "Speed: 0.9ms preprocess, 35.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 39.2ms\n",
      "Speed: 1.3ms preprocess, 39.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 36.5ms\n",
      "Speed: 0.8ms preprocess, 36.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Person, 35.3ms\n",
      "Speed: 0.7ms preprocess, 35.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Person, 39.3ms\n",
      "Speed: 1.2ms preprocess, 39.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Person, 36.0ms\n",
      "Speed: 0.7ms preprocess, 36.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Person, 37.1ms\n",
      "Speed: 0.8ms preprocess, 37.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 188.0ms\n",
      "Speed: 1.1ms preprocess, 188.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 54.6ms\n",
      "Speed: 1.4ms preprocess, 54.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.7ms\n",
      "Speed: 0.7ms preprocess, 35.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 37.5ms\n",
      "Speed: 0.8ms preprocess, 37.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.0ms\n",
      "Speed: 1.6ms preprocess, 34.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.8ms\n",
      "Speed: 1.2ms preprocess, 32.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 37.8ms\n",
      "Speed: 1.0ms preprocess, 37.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.7ms\n",
      "Speed: 1.0ms preprocess, 33.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Person, 37.2ms\n",
      "Speed: 1.1ms preprocess, 37.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.2ms\n",
      "Speed: 0.8ms preprocess, 32.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Person, 44.5ms\n",
      "Speed: 4.6ms preprocess, 44.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Boots, 1 Person, 30.2ms\n",
      "Speed: 1.1ms preprocess, 30.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.5ms\n",
      "Speed: 0.6ms preprocess, 34.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Person, 31.9ms\n",
      "Speed: 0.7ms preprocess, 31.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.1ms\n",
      "Speed: 0.8ms preprocess, 32.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.1ms\n",
      "Speed: 0.7ms preprocess, 34.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.8ms\n",
      "Speed: 1.0ms preprocess, 30.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Person, 35.1ms\n",
      "Speed: 1.1ms preprocess, 35.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Person, 30.6ms\n",
      "Speed: 1.0ms preprocess, 30.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 36.2ms\n",
      "Speed: 1.0ms preprocess, 36.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 36.1ms\n",
      "Speed: 1.0ms preprocess, 36.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Person, 33.6ms\n",
      "Speed: 0.7ms preprocess, 33.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Person, 30.5ms\n",
      "Speed: 0.7ms preprocess, 30.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Person, 29.7ms\n",
      "Speed: 0.9ms preprocess, 29.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.6ms\n",
      "Speed: 1.7ms preprocess, 30.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.8ms\n",
      "Speed: 1.2ms preprocess, 33.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.8ms\n",
      "Speed: 0.9ms preprocess, 29.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Boots, 32.3ms\n",
      "Speed: 1.1ms preprocess, 32.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.6ms\n",
      "Speed: 0.9ms preprocess, 32.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Helmet, 32.3ms\n",
      "Speed: 1.0ms preprocess, 32.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Helmet, 30.0ms\n",
      "Speed: 0.9ms preprocess, 30.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Helmet, 1 Person, 31.6ms\n",
      "Speed: 0.8ms preprocess, 31.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Helmet, 1 Person, 32.1ms\n",
      "Speed: 0.9ms preprocess, 32.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Helmet, 1 Person, 32.6ms\n",
      "Speed: 0.8ms preprocess, 32.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Helmet, 1 Person, 33.0ms\n",
      "Speed: 0.8ms preprocess, 33.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Helmet, 1 Person, 35.2ms\n",
      "Speed: 0.6ms preprocess, 35.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Helmet, 1 Person, 35.5ms\n",
      "Speed: 0.8ms preprocess, 35.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Helmet, 1 Person, 41.1ms\n",
      "Speed: 1.0ms preprocess, 41.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Helmet, 1 Person, 36.4ms\n",
      "Speed: 0.8ms preprocess, 36.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Helmet, 1 Person, 33.7ms\n",
      "Speed: 0.8ms preprocess, 33.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Helmet, 1 Person, 34.6ms\n",
      "Speed: 0.7ms preprocess, 34.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Helmets, 1 Person, 30.5ms\n",
      "Speed: 0.9ms preprocess, 30.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.8ms\n",
      "Speed: 0.8ms preprocess, 33.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.6ms\n",
      "Speed: 0.7ms preprocess, 33.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.7ms\n",
      "Speed: 0.7ms preprocess, 33.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Boots, 31.6ms\n",
      "Speed: 0.7ms preprocess, 31.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.4ms\n",
      "Speed: 0.7ms preprocess, 31.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.2ms\n",
      "Speed: 0.8ms preprocess, 35.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.8ms\n",
      "Speed: 0.7ms preprocess, 32.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Person, 43.6ms\n",
      "Speed: 0.8ms preprocess, 43.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Person, 34.1ms\n",
      "Speed: 0.6ms preprocess, 34.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Boots, 1 Person, 35.2ms\n",
      "Speed: 0.7ms preprocess, 35.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Person, 32.1ms\n",
      "Speed: 0.8ms preprocess, 32.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Person, 33.2ms\n",
      "Speed: 0.7ms preprocess, 33.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.1ms\n",
      "Speed: 0.6ms preprocess, 33.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Person, 31.4ms\n",
      "Speed: 0.7ms preprocess, 31.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Person, 33.3ms\n",
      "Speed: 0.6ms preprocess, 33.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Person, 31.5ms\n",
      "Speed: 0.8ms preprocess, 31.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Person, 103.9ms\n",
      "Speed: 0.7ms preprocess, 103.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.3ms\n",
      "Speed: 0.8ms preprocess, 32.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.0ms\n",
      "Speed: 0.7ms preprocess, 32.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Person, 34.1ms\n",
      "Speed: 0.9ms preprocess, 34.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Person, 31.4ms\n",
      "Speed: 0.9ms preprocess, 31.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Person, 31.5ms\n",
      "Speed: 0.7ms preprocess, 31.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Person, 31.1ms\n",
      "Speed: 0.7ms preprocess, 31.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.6ms\n",
      "Speed: 0.6ms preprocess, 32.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.0ms\n",
      "Speed: 0.7ms preprocess, 31.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Person, 38.5ms\n",
      "Speed: 0.9ms preprocess, 38.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Boots, 1 Person, 34.6ms\n",
      "Speed: 1.4ms preprocess, 34.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Person, 34.2ms\n",
      "Speed: 0.6ms preprocess, 34.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Person, 32.1ms\n",
      "Speed: 0.9ms preprocess, 32.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.2ms\n",
      "Speed: 0.8ms preprocess, 33.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Person, 29.3ms\n",
      "Speed: 0.8ms preprocess, 29.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Person, 30.5ms\n",
      "Speed: 0.9ms preprocess, 30.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Person, 33.3ms\n",
      "Speed: 0.8ms preprocess, 33.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Persons, 35.2ms\n",
      "Speed: 1.0ms preprocess, 35.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Persons, 35.1ms\n",
      "Speed: 1.0ms preprocess, 35.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Persons, 34.7ms\n",
      "Speed: 0.8ms preprocess, 34.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Persons, 36.3ms\n",
      "Speed: 0.9ms preprocess, 36.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Persons, 34.5ms\n",
      "Speed: 1.0ms preprocess, 34.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Bootss, 1 Helmet, 1 Person, 2 Vests, 31.1ms\n",
      "Speed: 0.9ms preprocess, 31.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Boots, 2 Helmets, 1 Person, 1 Vest, 32.1ms\n",
      "Speed: 1.7ms preprocess, 32.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Boots, 1 Helmet, 1 Person, 1 Vest, 30.9ms\n",
      "Speed: 0.7ms preprocess, 30.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Bootss, 1 Helmet, 1 Person, 1 Vest, 31.3ms\n",
      "Speed: 1.2ms preprocess, 31.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 Bootss, 1 Person, 2 Vests, 33.1ms\n",
      "Speed: 0.9ms preprocess, 33.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Bootss, 2 Persons, 4 Vests, 32.0ms\n",
      "Speed: 0.9ms preprocess, 32.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Persons, 3 Vests, 35.4ms\n",
      "Speed: 0.8ms preprocess, 35.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Helmet, 3 Persons, 3 Vests, 33.4ms\n",
      "Speed: 0.6ms preprocess, 33.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Bootss, 1 Helmet, 3 Persons, 3 Vests, 32.2ms\n",
      "Speed: 0.8ms preprocess, 32.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Bootss, 3 Persons, 3 Vests, 35.6ms\n",
      "Speed: 0.9ms preprocess, 35.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 Bootss, 1 Helmet, 3 Persons, 3 Vests, 34.5ms\n",
      "Speed: 1.7ms preprocess, 34.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Bootss, 1 Helmet, 4 Persons, 3 Vests, 34.4ms\n",
      "Speed: 0.9ms preprocess, 34.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Bootss, 2 Helmets, 5 Persons, 3 Vests, 35.5ms\n",
      "Speed: 0.8ms preprocess, 35.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Helmets, 4 Persons, 4 Vests, 32.0ms\n",
      "Speed: 1.1ms preprocess, 32.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Bootss, 3 Helmets, 4 Persons, 4 Vests, 33.8ms\n",
      "Speed: 0.9ms preprocess, 33.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Bootss, 1 Helmet, 4 Persons, 4 Vests, 33.4ms\n",
      "Speed: 0.8ms preprocess, 33.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Boots, 1 Helmet, 4 Persons, 4 Vests, 34.3ms\n",
      "Speed: 0.6ms preprocess, 34.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Bootss, 4 Persons, 4 Vests, 35.9ms\n",
      "Speed: 0.9ms preprocess, 35.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Boots, 4 Persons, 4 Vests, 34.1ms\n",
      "Speed: 0.7ms preprocess, 34.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Boots, 4 Persons, 4 Vests, 33.0ms\n",
      "Speed: 0.7ms preprocess, 33.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Persons, 4 Vests, 37.1ms\n",
      "Speed: 0.9ms preprocess, 37.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Helmet, 2 Persons, 4 Vests, 33.5ms\n",
      "Speed: 0.8ms preprocess, 33.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Person, 3 Vests, 33.8ms\n",
      "Speed: 0.7ms preprocess, 33.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Person, 2 Vests, 34.2ms\n",
      "Speed: 0.9ms preprocess, 34.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Boots, 1 Person, 3 Vests, 34.7ms\n",
      "Speed: 0.6ms preprocess, 34.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Boots, 1 Helmet, 1 Person, 2 Vests, 31.7ms\n",
      "Speed: 0.7ms preprocess, 31.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Boots, 1 Person, 2 Vests, 33.4ms\n",
      "Speed: 0.8ms preprocess, 33.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Boots, 1 Person, 2 Vests, 34.7ms\n",
      "Speed: 0.8ms preprocess, 34.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Boots, 1 Person, 1 Vest, 30.0ms\n",
      "Speed: 0.9ms preprocess, 30.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Boots, 1 Vest, 30.7ms\n",
      "Speed: 0.7ms preprocess, 30.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Boots, 1 Vest, 31.8ms\n",
      "Speed: 1.0ms preprocess, 31.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Bootss, 1 Helmet, 31.3ms\n",
      "Speed: 0.6ms preprocess, 31.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Boots, 1 Person, 32.8ms\n",
      "Speed: 1.1ms preprocess, 32.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Helmet, 1 Person, 32.1ms\n",
      "Speed: 0.6ms preprocess, 32.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Boots, 1 Helmet, 1 Person, 31.8ms\n",
      "Speed: 0.6ms preprocess, 31.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Bootss, 1 Person, 31.8ms\n",
      "Speed: 1.1ms preprocess, 31.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Bootss, 1 Helmet, 1 Person, 32.5ms\n",
      "Speed: 0.9ms preprocess, 32.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Bootss, 1 Person, 1 Vest, 30.8ms\n",
      "Speed: 0.9ms preprocess, 30.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Bootss, 1 Person, 2 Vests, 29.5ms\n",
      "Speed: 0.7ms preprocess, 29.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 Bootss, 1 Person, 1 Vest, 31.8ms\n",
      "Speed: 0.8ms preprocess, 31.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 Bootss, 2 Persons, 1 Vest, 31.1ms\n",
      "Speed: 1.1ms preprocess, 31.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Boots, 1 Person, 1 Vest, 30.9ms\n",
      "Speed: 0.7ms preprocess, 30.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Bootss, 1 Person, 1 Vest, 30.6ms\n",
      "Speed: 1.1ms preprocess, 30.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Bootss, 2 Persons, 1 Vest, 31.2ms\n",
      "Speed: 1.0ms preprocess, 31.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Bootss, 3 Persons, 2 Vests, 35.6ms\n",
      "Speed: 0.7ms preprocess, 35.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Bootss, 1 Person, 2 Vests, 33.0ms\n",
      "Speed: 0.9ms preprocess, 33.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Bootss, 1 Person, 2 Vests, 33.5ms\n",
      "Speed: 0.9ms preprocess, 33.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 Bootss, 1 Person, 2 Vests, 33.9ms\n",
      "Speed: 1.0ms preprocess, 33.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Bootss, 3 Persons, 2 Vests, 34.0ms\n",
      "Speed: 0.6ms preprocess, 34.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 Bootss, 2 Persons, 2 Vests, 34.7ms\n",
      "Speed: 1.4ms preprocess, 34.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 Bootss, 3 Persons, 2 Vests, 31.4ms\n",
      "Speed: 1.1ms preprocess, 31.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 Bootss, 2 Persons, 2 Vests, 34.1ms\n",
      "Speed: 0.8ms preprocess, 34.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Bootss, 3 Persons, 2 Vests, 32.5ms\n",
      "Speed: 0.8ms preprocess, 32.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Bootss, 2 Persons, 2 Vests, 30.7ms\n",
      "Speed: 1.0ms preprocess, 30.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 Bootss, 3 Persons, 2 Vests, 29.6ms\n",
      "Speed: 0.7ms preprocess, 29.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 Bootss, 1 Helmet, 4 Persons, 2 Vests, 33.5ms\n",
      "Speed: 1.1ms preprocess, 33.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 Bootss, 1 Helmet, 4 Persons, 2 Vests, 29.7ms\n",
      "Speed: 0.8ms preprocess, 29.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Bootss, 4 Persons, 2 Vests, 34.2ms\n",
      "Speed: 1.0ms preprocess, 34.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Bootss, 3 Persons, 2 Vests, 28.9ms\n",
      "Speed: 0.9ms preprocess, 28.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Bootss, 4 Persons, 2 Vests, 32.2ms\n",
      "Speed: 1.0ms preprocess, 32.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Bootss, 2 Persons, 3 Vests, 29.1ms\n",
      "Speed: 1.5ms preprocess, 29.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Bootss, 3 Persons, 2 Vests, 65.3ms\n",
      "Speed: 2.7ms preprocess, 65.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Bootss, 2 Persons, 2 Vests, 32.7ms\n",
      "Speed: 0.9ms preprocess, 32.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 Bootss, 3 Persons, 2 Vests, 31.1ms\n",
      "Speed: 1.0ms preprocess, 31.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Bootss, 3 Persons, 2 Vests, 37.5ms\n",
      "Speed: 0.7ms preprocess, 37.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 Bootss, 4 Persons, 2 Vests, 35.6ms\n",
      "Speed: 0.6ms preprocess, 35.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Bootss, 5 Persons, 2 Vests, 33.7ms\n",
      "Speed: 0.6ms preprocess, 33.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Bootss, 3 Persons, 2 Vests, 32.4ms\n",
      "Speed: 0.8ms preprocess, 32.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 Bootss, 3 Persons, 1 Vest, 33.8ms\n",
      "Speed: 1.0ms preprocess, 33.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 Bootss, 1 Helmet, 3 Persons, 1 Vest, 35.1ms\n",
      "Speed: 1.2ms preprocess, 35.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 Bootss, 3 Persons, 1 Vest, 31.9ms\n",
      "Speed: 0.9ms preprocess, 31.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 Bootss, 3 Persons, 1 Vest, 34.9ms\n",
      "Speed: 0.8ms preprocess, 34.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 Bootss, 2 Persons, 1 Vest, 35.1ms\n",
      "Speed: 0.8ms preprocess, 35.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 Bootss, 2 Persons, 1 Vest, 32.5ms\n",
      "Speed: 0.7ms preprocess, 32.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 Bootss, 2 Persons, 31.9ms\n",
      "Speed: 0.8ms preprocess, 31.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 Bootss, 2 Persons, 32.1ms\n",
      "Speed: 0.7ms preprocess, 32.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 Bootss, 2 Persons, 31.8ms\n",
      "Speed: 0.9ms preprocess, 31.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 Bootss, 2 Persons, 31.8ms\n",
      "Speed: 0.8ms preprocess, 31.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 Bootss, 3 Persons, 34.2ms\n",
      "Speed: 0.7ms preprocess, 34.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 Bootss, 3 Persons, 38.2ms\n",
      "Speed: 1.0ms preprocess, 38.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 Bootss, 2 Persons, 35.3ms\n",
      "Speed: 0.7ms preprocess, 35.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 Bootss, 3 Persons, 35.4ms\n",
      "Speed: 0.8ms preprocess, 35.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 Bootss, 2 Persons, 33.8ms\n",
      "Speed: 0.9ms preprocess, 33.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 Bootss, 2 Persons, 33.3ms\n",
      "Speed: 0.8ms preprocess, 33.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Bootss, 2 Persons, 34.7ms\n",
      "Speed: 0.7ms preprocess, 34.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Bootss, 2 Persons, 31.6ms\n",
      "Speed: 0.8ms preprocess, 31.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Bootss, 2 Persons, 31.7ms\n",
      "Speed: 0.6ms preprocess, 31.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Bootss, 2 Persons, 35.1ms\n",
      "Speed: 3.1ms preprocess, 35.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Bootss, 2 Persons, 34.6ms\n",
      "Speed: 1.2ms preprocess, 34.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 Bootss, 2 Persons, 1 Vest, 34.0ms\n",
      "Speed: 0.8ms preprocess, 34.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 Bootss, 2 Persons, 32.6ms\n",
      "Speed: 0.6ms preprocess, 32.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 Bootss, 2 Persons, 33.7ms\n",
      "Speed: 0.7ms preprocess, 33.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Bootss, 2 Persons, 32.9ms\n",
      "Speed: 0.8ms preprocess, 32.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 Bootss, 2 Persons, 28.9ms\n",
      "Speed: 0.8ms preprocess, 28.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 Bootss, 3 Persons, 35.1ms\n",
      "Speed: 0.7ms preprocess, 35.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 Bootss, 3 Persons, 31.7ms\n",
      "Speed: 0.7ms preprocess, 31.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 Bootss, 2 Persons, 31.8ms\n",
      "Speed: 0.6ms preprocess, 31.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 Bootss, 2 Persons, 31.8ms\n",
      "Speed: 0.6ms preprocess, 31.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Bootss, 2 Persons, 30.1ms\n",
      "Speed: 1.1ms preprocess, 30.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 Bootss, 2 Persons, 31.7ms\n",
      "Speed: 0.7ms preprocess, 31.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 Bootss, 2 Persons, 31.8ms\n",
      "Speed: 0.8ms preprocess, 31.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 Bootss, 2 Persons, 28.5ms\n",
      "Speed: 0.7ms preprocess, 28.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Open a video capture (0 for the default camera, or provide a file path)\n",
    "video_path = \"/Users/aryan/Desktop/moondream-variphi/LMS_Experiment/Object_detection_video/construction-site-video.mp4\"  # Change this to your video file path\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "count = 0\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    count += 1\n",
    "\n",
    "    # Process every 50th frame\n",
    "    if count % 10 == 0:\n",
    "        result = model(frame)\n",
    "        annotated_frame = result[0].plot()\n",
    "        cv2.imshow(\"YOLOv8 Detection\", annotated_frame)\n",
    "\n",
    "        # Wait for 'q' key to quit, else wait 1 ms\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540f42b5",
   "metadata": {},
   "source": [
    "## YouTube Live Stream Processing with YOLO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08f9ab6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yt-dlp\n",
      "  Using cached yt_dlp-2025.11.12-py3-none-any.whl.metadata (180 kB)\n",
      "Using cached yt_dlp-2025.11.12-py3-none-any.whl (3.3 MB)\n",
      "Installing collected packages: yt-dlp\n",
      "Successfully installed yt-dlp-2025.11.12\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install yt-dlp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a7efec",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bf14595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting stream URL from YouTube...\n",
      "Stream URL extracted successfully!\n",
      "Stream URL: https://manifest.googlevideo.com/api/manifest/hls_playlist/expire/1764860166/ei/pkwxafzcOMSN9fwP-76n...\n"
     ]
    }
   ],
   "source": [
    "# Install yt-dlp if you haven't already\n",
    "# !pip install yt-dlp\n",
    "\n",
    "import subprocess\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "def get_youtube_stream_url(youtube_url):\n",
    "    \"\"\"\n",
    "    Extract the direct stream URL from a YouTube video/live stream\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Use yt-dlp to get the best video stream URL\n",
    "        cmd = [\n",
    "            'yt-dlp',\n",
    "            '-f', 'best[ext=mp4]/best',  # Get best quality mp4 or best available\n",
    "            '-g',  # Get URL only\n",
    "            youtube_url\n",
    "        ]\n",
    "        \n",
    "        result = subprocess.run(cmd, capture_output=True, text=True, check=True)\n",
    "        stream_url = result.stdout.strip()\n",
    "        return stream_url\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error extracting stream URL: {e}\")\n",
    "        return None\n",
    "\n",
    "# YouTube live stream URL\n",
    "youtube_url = \"https://www.youtube.com/watch?v=HiOvVp-wMj0\"\n",
    "\n",
    "print(\"Extracting stream URL from YouTube...\")\n",
    "stream_url = get_youtube_stream_url(youtube_url)\n",
    "\n",
    "if stream_url:\n",
    "    print(f\"Stream URL extracted successfully!\")\n",
    "    print(f\"Stream URL: {stream_url[:100]}...\")  # Print first 100 chars\n",
    "else:\n",
    "    print(\"Failed to extract stream URL\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe30bd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17539087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stream opened successfully! Starting YOLO detection...\n",
      "\n",
      "0: 384x640 4 traffic lights, 41.0ms\n",
      "Speed: 3.0ms preprocess, 41.0ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processed frame 50\n",
      "\n",
      "0: 384x640 1 car, 4 traffic lights, 38.4ms\n",
      "Speed: 2.7ms preprocess, 38.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processed frame 100\n",
      "\n",
      "0: 384x640 1 car, 4 traffic lights, 38.1ms\n",
      "Speed: 2.0ms preprocess, 38.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processed frame 150\n",
      "\n",
      "0: 384x640 1 car, 4 traffic lights, 36.7ms\n",
      "Speed: 1.8ms preprocess, 36.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processed frame 200\n",
      "\n",
      "0: 384x640 1 car, 4 traffic lights, 41.9ms\n",
      "Speed: 3.4ms preprocess, 41.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processed frame 250\n",
      "\n",
      "0: 384x640 1 car, 4 traffic lights, 36.7ms\n",
      "Speed: 1.6ms preprocess, 36.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processed frame 300\n",
      "\n",
      "0: 384x640 1 car, 4 traffic lights, 42.0ms\n",
      "Speed: 2.2ms preprocess, 42.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processed frame 350\n",
      "\n",
      "0: 384x640 2 cars, 5 traffic lights, 41.0ms\n",
      "Speed: 2.6ms preprocess, 41.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processed frame 400\n",
      "\n",
      "0: 384x640 1 car, 4 traffic lights, 40.3ms\n",
      "Speed: 3.9ms preprocess, 40.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processed frame 450\n",
      "\n",
      "0: 384x640 5 traffic lights, 38.5ms\n",
      "Speed: 2.4ms preprocess, 38.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processed frame 500\n",
      "\n",
      "0: 384x640 5 traffic lights, 36.9ms\n",
      "Speed: 1.9ms preprocess, 36.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processed frame 550\n",
      "\n",
      "0: 384x640 1 car, 3 traffic lights, 37.8ms\n",
      "Speed: 2.2ms preprocess, 37.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processed frame 600\n",
      "\n",
      "0: 384x640 1 car, 3 traffic lights, 35.1ms\n",
      "Speed: 2.5ms preprocess, 35.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processed frame 650\n",
      "\n",
      "0: 384x640 3 cars, 4 traffic lights, 40.0ms\n",
      "Speed: 2.7ms preprocess, 40.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processed frame 700\n",
      "\n",
      "0: 384x640 1 car, 5 traffic lights, 48.0ms\n",
      "Speed: 3.6ms preprocess, 48.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processed frame 750\n",
      "\n",
      "0: 384x640 1 car, 6 traffic lights, 40.2ms\n",
      "Speed: 2.4ms preprocess, 40.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processed frame 800\n",
      "\n",
      "0: 384x640 1 car, 4 traffic lights, 38.4ms\n",
      "Speed: 2.0ms preprocess, 38.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processed frame 850\n",
      "\n",
      "0: 384x640 2 cars, 6 traffic lights, 36.6ms\n",
      "Speed: 2.3ms preprocess, 36.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processed frame 900\n",
      "\n",
      "0: 384x640 6 traffic lights, 39.5ms\n",
      "Speed: 2.9ms preprocess, 39.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processed frame 950\n",
      "\n",
      "0: 384x640 8 traffic lights, 48.9ms\n",
      "Speed: 2.3ms preprocess, 48.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processed frame 1000\n",
      "\n",
      "0: 384x640 7 traffic lights, 34.2ms\n",
      "Speed: 2.1ms preprocess, 34.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processed frame 1050\n",
      "\n",
      "0: 384x640 6 traffic lights, 33.9ms\n",
      "Speed: 1.9ms preprocess, 33.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processed frame 1100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m count = \u001b[32m0\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     ret, frame = \u001b[43mcap\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n\u001b[32m     15\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFailed to read frame, stream might have ended or connection lost\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Process YouTube live stream with YOLO\n",
    "if stream_url:\n",
    "    cap = cv2.VideoCapture(stream_url)\n",
    "    \n",
    "    # Check if stream opened successfully\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video stream\")\n",
    "    else:\n",
    "        print(\"Stream opened successfully! Starting YOLO detection...\")\n",
    "        \n",
    "        count = 0\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Failed to read frame, stream might have ended or connection lost\")\n",
    "                break\n",
    "            \n",
    "            count += 1\n",
    "            \n",
    "            # Process every 50th frame (adjust as needed for live stream)\n",
    "            if count % 50 == 0:\n",
    "                result = model(frame)\n",
    "                annotated_frame = result[0].plot()\n",
    "                cv2.imshow(\"YOLOv8 Live Detection\", annotated_frame)\n",
    "                print(f\"Processed frame {count}\")\n",
    "            \n",
    "            # Wait for 'q' key to quit, else wait 1 ms\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"Stream processing stopped\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "118a2e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets do the monitering !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01a4ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlflow\n",
      "  Downloading mlflow-3.7.0-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting mlflow-skinny==3.7.0 (from mlflow)\n",
      "  Downloading mlflow_skinny-3.7.0-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting mlflow-tracing==3.7.0 (from mlflow)\n",
      "  Downloading mlflow_tracing-3.7.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting Flask-CORS<7 (from mlflow)\n",
      "  Downloading flask_cors-6.0.1-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting Flask<4 (from mlflow)\n",
      "  Using cached flask-3.1.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
      "  Downloading alembic-1.17.2-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting cryptography<47,>=43.0.0 (from mlflow)\n",
      "  Using cached cryptography-46.0.3-cp311-abi3-macosx_10_9_universal2.whl.metadata (5.7 kB)\n",
      "Collecting docker<8,>=4.0.0 (from mlflow)\n",
      "  Using cached docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting graphene<4 (from mlflow)\n",
      "  Using cached graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting gunicorn<24 (from mlflow)\n",
      "  Using cached gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting huey<3,>=2.5.0 (from mlflow)\n",
      "  Downloading huey-2.5.5-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: matplotlib<4 in /Users/aryan/Desktop/moondream-variphi/venv/lib/python3.11/site-packages (from mlflow) (3.7.5)\n",
      "Requirement already satisfied: numpy<3 in /Users/aryan/Desktop/moondream-variphi/venv/lib/python3.11/site-packages (from mlflow) (1.26.4)\n",
      "Requirement already satisfied: pandas<3 in /Users/aryan/Desktop/moondream-variphi/venv/lib/python3.11/site-packages (from mlflow) (2.3.3)\n",
      "Requirement already satisfied: pyarrow<23,>=4.0.0 in /Users/aryan/Desktop/moondream-variphi/venv/lib/python3.11/site-packages (from mlflow) (14.0.2)\n",
      "Requirement already satisfied: scikit-learn<2 in /Users/aryan/Desktop/moondream-variphi/venv/lib/python3.11/site-packages (from mlflow) (1.7.2)\n",
      "Requirement already satisfied: scipy<2 in /Users/aryan/Desktop/moondream-variphi/venv/lib/python3.11/site-packages (from mlflow) (1.10.1)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /Users/aryan/Desktop/moondream-variphi/venv/lib/python3.11/site-packages (from mlflow) (2.0.43)\n",
      "Requirement already satisfied: cachetools<7,>=5.0.0 in /Users/aryan/Desktop/moondream-variphi/venv/lib/python3.11/site-packages (from mlflow-skinny==3.7.0->mlflow) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in /Users/aryan/Desktop/moondream-variphi/venv/lib/python3.11/site-packages (from mlflow-skinny==3.7.0->mlflow) (8.2.1)\n",
      "Collecting cloudpickle<4 (from mlflow-skinny==3.7.0->mlflow)\n",
      "  Downloading cloudpickle-3.1.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.7.0->mlflow)\n",
      "  Downloading databricks_sdk-0.73.0-py3-none-any.whl.metadata (40 kB)\n",
      "Requirement already satisfied: fastapi<1 in /Users/aryan/Desktop/moondream-variphi/venv/lib/python3.11/site-packages (from mlflow-skinny==3.7.0->mlflow) (0.115.14)\n",
      "Collecting gitpython<4,>=3.1.9 (from mlflow-skinny==3.7.0->mlflow)\n",
      "  Using cached gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /Users/aryan/Desktop/moondream-variphi/venv/lib/python3.11/site-packages (from mlflow-skinny==3.7.0->mlflow) (8.7.0)\n",
      "Collecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny==3.7.0->mlflow)\n",
      "  Downloading opentelemetry_api-1.39.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-proto<3,>=1.9.0 (from mlflow-skinny==3.7.0->mlflow)\n",
      "  Downloading opentelemetry_proto-1.39.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==3.7.0->mlflow)\n",
      "  Downloading opentelemetry_sdk-1.39.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: packaging<26 in /Users/aryan/Desktop/moondream-variphi/venv/lib/python3.11/site-packages (from mlflow-skinny==3.7.0->mlflow) (23.2)\n",
      "Requirement already satisfied: protobuf<7,>=3.12.0 in /Users/aryan/Desktop/moondream-variphi/venv/lib/python3.11/site-packages (from mlflow-skinny==3.7.0->mlflow) (6.32.0)\n",
      "Requirement already satisfied: pydantic<3,>=2.0.0 in /Users/aryan/Desktop/moondream-variphi/venv/lib/python3.11/site-packages (from mlflow-skinny==3.7.0->mlflow) (2.12.2)\n",
      "Requirement already satisfied: python-dotenv<2,>=0.19.0 in /Users/aryan/Desktop/moondream-variphi/venv/lib/python3.11/site-packages (from mlflow-skinny==3.7.0->mlflow) (1.1.1)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /Users/aryan/Desktop/moondream-variphi/venv/lib/python3.11/site-packages (from mlflow-skinny==3.7.0->mlflow) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /Users/aryan/Desktop/moondream-variphi/venv/lib/python3.11/site-packages (from mlflow-skinny==3.7.0->mlflow) (2.32.5)\n",
      "Collecting sqlparse<1,>=0.4.0 (from mlflow-skinny==3.7.0->mlflow)\n",
      "  Downloading sqlparse-0.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /Users/aryan/Desktop/moondream-variphi/venv/lib/python3.11/site-packages (from mlflow-skinny==3.7.0->mlflow) (4.14.1)\n",
      "Requirement already satisfied: uvicorn<1 in /Users/aryan/Desktop/moondream-variphi/venv/lib/python3.11/site-packages (from mlflow-skinny==3.7.0->mlflow) (0.35.0)\n",
      "Collecting Mako (from alembic!=1.10.0,<2->mlflow)\n",
      "  Using cached mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting cffi>=2.0.0 (from cryptography<47,>=43.0.0->mlflow)\n",
      "  Using cached cffi-2.0.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: google-auth~=2.0 in /Users/aryan/Desktop/moondream-variphi/venv/lib/python3.11/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.7.0->mlflow) (2.40.3)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Users/aryan/Desktop/moondream-variphi/venv/lib/python3.11/site-packages (from docker<8,>=4.0.0->mlflow) (2.5.0)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /Users/aryan/Desktop/moondream-variphi/venv/lib/python3.11/site-packages (from fastapi<1->mlflow-skinny==3.7.0->mlflow) (0.46.2)\n",
      "Collecting blinker>=1.9.0 (from Flask<4->mlflow)\n",
      "  Using cached blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting itsdangerous>=2.2.0 (from Flask<4->mlflow)\n",
      "  Using cached itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: jinja2>=3.1.2 in /Users/aryan/Desktop/moondream-variphi/venv/lib/python3.11/site-packages (from Flask<4->mlflow) (3.1.6)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in /Users/aryan/Desktop/moondream-variphi/venv/lib/python3.11/site-packages (from Flask<4->mlflow) (3.0.2)\n",
      "Collecting werkzeug>=3.1.0 (from Flask<4->mlflow)\n",
      "  Downloading werkzeug-3.1.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=3.1.9->mlflow-skinny==3.7.0->mlflow)\n",
      "  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.7.0->mlflow)\n",
      "  Using cached smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/aryan/Desktop/moondream-variphi/venv/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.7.0->mlflow) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/aryan/Desktop/moondream-variphi/venv/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.7.0->mlflow) (4.9.1)\n",
      "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Downloading graphql_core-3.2.7-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Using cached graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /Users/aryan/Desktop/moondream-variphi/venv/lib/python3.11/site-packages (from graphene<4->mlflow) (2.9.0.post0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/aryan/Desktop/moondream-variphi/venv/lib/python3.11/site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.7.0->mlflow) (3.23.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/aryan/Desktop/moondream-variphi/venv/lib/python3.11/site-packages (from matplotlib<4->mlflow) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/aryan/Desktop/moondream-variphi/venv/lib/python3.11/site-packages (from matplotlib<4->mlflow) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/aryan/Desktop/moondream-variphi/venv/lib/python3.11/site-packages (from matplotlib<4->mlflow) (4.58.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/aryan/Desktop/moondream-variphi/venv/lib/python3.11/site-packages (from matplotlib<4->mlflow) (1.4.8)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/aryan/Desktop/moondream-variphi/venv/lib/python3.11/site-packages (from matplotlib<4->mlflow) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/aryan/Desktop/moondream-variphi/venv/lib/python3.11/site-packages (from matplotlib<4->mlflow) (3.2.3)\n",
      "Collecting opentelemetry-semantic-conventions==0.60b0 (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.7.0->mlflow)\n",
      "  Downloading opentelemetry_semantic_conventions-0.60b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/aryan/Desktop/moondream-variphi/venv/lib/python3.11/site-packages (from pandas<3->mlflow) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/aryan/Desktop/moondream-variphi/venv/lib/python3.11/site-packages (from pandas<3->mlflow) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/aryan/Desktop/moondream-variphi/venv/lib/python3.11/site-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.7.0->mlflow) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /Users/aryan/Desktop/moondream-variphi/venv/lib/python3.11/site-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.7.0->mlflow) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/aryan/Desktop/moondream-variphi/venv/lib/python3.11/site-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.7.0->mlflow) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/aryan/Desktop/moondream-variphi/venv/lib/python3.11/site-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/aryan/Desktop/moondream-variphi/venv/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.7.0->mlflow) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/aryan/Desktop/moondream-variphi/venv/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.7.0->mlflow) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/aryan/Desktop/moondream-variphi/venv/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.7.0->mlflow) (2025.6.15)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/aryan/Desktop/moondream-variphi/venv/lib/python3.11/site-packages (from rsa<5,>=3.1.4->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.7.0->mlflow) (0.6.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/aryan/Desktop/moondream-variphi/venv/lib/python3.11/site-packages (from scikit-learn<2->mlflow) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/aryan/Desktop/moondream-variphi/venv/lib/python3.11/site-packages (from scikit-learn<2->mlflow) (3.6.0)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /Users/aryan/Desktop/moondream-variphi/venv/lib/python3.11/site-packages (from starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==3.7.0->mlflow) (3.7.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/aryan/Desktop/moondream-variphi/venv/lib/python3.11/site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==3.7.0->mlflow) (1.3.1)\n",
      "Requirement already satisfied: h11>=0.8 in /Users/aryan/Desktop/moondream-variphi/venv/lib/python3.11/site-packages (from uvicorn<1->mlflow-skinny==3.7.0->mlflow) (0.16.0)\n",
      "Requirement already satisfied: pycparser in /Users/aryan/Desktop/moondream-variphi/venv/lib/python3.11/site-packages (from cffi>=2.0.0->cryptography<47,>=43.0.0->mlflow) (2.22)\n",
      "Downloading mlflow-3.7.0-py3-none-any.whl (8.9 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading mlflow_skinny-3.7.0-py3-none-any.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading mlflow_tracing-3.7.0-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading alembic-1.17.2-py3-none-any.whl (248 kB)\n",
      "Downloading cloudpickle-3.1.2-py3-none-any.whl (22 kB)\n",
      "Using cached cryptography-46.0.3-cp311-abi3-macosx_10_9_universal2.whl (7.2 MB)\n",
      "Downloading databricks_sdk-0.73.0-py3-none-any.whl (753 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m753.9/753.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m36m-:--:--\u001b[0m\n",
      "\u001b[?25hUsing cached docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "Using cached flask-3.1.2-py3-none-any.whl (103 kB)\n",
      "Downloading flask_cors-6.0.1-py3-none-any.whl (13 kB)\n",
      "Using cached gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
      "Using cached gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Using cached graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
      "Downloading graphql_core-3.2.7-py3-none-any.whl (207 kB)\n",
      "Using cached graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
      "Using cached gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
      "Downloading huey-2.5.5-py3-none-any.whl (76 kB)\n",
      "Downloading opentelemetry_api-1.39.0-py3-none-any.whl (66 kB)\n",
      "Downloading opentelemetry_proto-1.39.0-py3-none-any.whl (72 kB)\n",
      "Downloading opentelemetry_sdk-1.39.0-py3-none-any.whl (132 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.60b0-py3-none-any.whl (219 kB)\n",
      "Using cached smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Downloading sqlparse-0.5.4-py3-none-any.whl (45 kB)\n",
      "Using cached blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Using cached cffi-2.0.0-cp311-cp311-macosx_11_0_arm64.whl (180 kB)\n",
      "Using cached itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading werkzeug-3.1.4-py3-none-any.whl (224 kB)\n",
      "Using cached mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: huey, werkzeug, sqlparse, smmap, opentelemetry-proto, Mako, itsdangerous, gunicorn, graphql-core, cloudpickle, cffi, blinker, opentelemetry-api, graphql-relay, gitdb, Flask, docker, cryptography, alembic, opentelemetry-semantic-conventions, graphene, gitpython, Flask-CORS, databricks-sdk, opentelemetry-sdk, mlflow-tracing, mlflow-skinny, mlflow\n",
      "\u001b[2K  Attempting uninstall: cffim\u001b[0m\u001b[90m\u001b[0m \u001b[32m 9/28\u001b[0m [cloudpickle]\n",
      "\u001b[2K    Found existing installation: cffi 1.17.1\u001b[0m \u001b[32m 9/28\u001b[0m [cloudpickle]\n",
      "\u001b[2K    Uninstalling cffi-1.17.1:m\u001b[90m\u001b[0m \u001b[32m 9/28\u001b[0m [cloudpickle]\n",
      "\u001b[2K      Successfully uninstalled cffi-1.17.1\u001b[0m \u001b[32m10/28\u001b[0m [cffi]le]\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m28/28\u001b[0m [mlflow]27/28\u001b[0m [mlflow]skinny]]pi]\n",
      "\u001b[1A\u001b[2KSuccessfully installed Flask-3.1.2 Flask-CORS-6.0.1 Mako-1.3.10 alembic-1.17.2 blinker-1.9.0 cffi-2.0.0 cloudpickle-3.1.2 cryptography-46.0.3 databricks-sdk-0.73.0 docker-7.1.0 gitdb-4.0.12 gitpython-3.1.45 graphene-3.4.3 graphql-core-3.2.7 graphql-relay-3.2.0 gunicorn-23.0.0 huey-2.5.5 itsdangerous-2.2.0 mlflow-3.7.0 mlflow-skinny-3.7.0 mlflow-tracing-3.7.0 opentelemetry-api-1.39.0 opentelemetry-proto-1.39.0 opentelemetry-sdk-1.39.0 opentelemetry-semantic-conventions-0.60b0 smmap-5.0.2 sqlparse-0.5.4 werkzeug-3.1.4\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "!pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a03f59f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
